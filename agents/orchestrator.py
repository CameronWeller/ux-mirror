#!/usr/bin/env python3
"""
UX-MIRROR Core Orchestrator Agent
================================

Primary agent responsible for coordinating all sub-agents, making decisions,
and providing centralized control of the UX intelligence system.

Author: UX-MIRROR System
Version: 1.0.0
"""

import asyncio
import logging
import json
import time
import uuid
from typing import Dict, List, Any, Optional, Set
from dataclasses import dataclass, asdict
from datetime import datetime, timedelta
from collections import defaultdict, deque
import websockets
import psutil
from enum import Enum

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class AgentStatus(Enum):
    """Agent status enumeration"""
    DISCONNECTED = "disconnected"
    CONNECTING = "connecting"
    ACTIVE = "active"
    ERROR = "error"
    OVERLOADED = "overloaded"

class TaskPriority(Enum):
    """Task priority levels"""
    LOW = 1
    MEDIUM = 2
    HIGH = 3
    CRITICAL = 4

@dataclass
class AgentInfo:
    """Information about a connected agent"""
    agent_id: str
    websocket: websockets.WebSocketServerProtocol
    capabilities: List[str]
    status: AgentStatus
    last_heartbeat: datetime
    current_load: float
    total_tasks_completed: int
    avg_response_time: float
    error_count: int
    registration_time: datetime

@dataclass
class Task:
    """Represents a task to be executed by agents"""
    task_id: str
    task_type: str
    priority: TaskPriority
    data: Dict[str, Any]
    assigned_agent: Optional[str]
    created_at: datetime
    deadline: Optional[datetime]
    retry_count: int
    max_retries: int
    status: str  # 'pending', 'assigned', 'in_progress', 'completed', 'failed'

@dataclass
class UXInsight:
    """Represents a UX insight generated by the system"""
    insight_id: str
    type: str
    severity: str
    description: str
    source_agents: List[str]
    confidence: float
    data: Dict[str, Any]
    created_at: datetime
    action_taken: Optional[str] = None

class OrchestratorAgent:
    """
    Core Orchestrator Agent for UX-MIRROR system.
    
    Responsibilities:
    - Agent lifecycle management
    - Task scheduling and load balancing
    - Decision making and insight generation
    - Configuration management
    - System monitoring and health checks
    """
    
    def __init__(self, host: str = "localhost", port: int = 8765):
        self.host = host
        self.port = port
        self.server = None
        
        # Agent management
        self.connected_agents: Dict[str, AgentInfo] = {}
        self.agent_capabilities: Dict[str, Set[str]] = defaultdict(set)
        
        # Task management
        self.task_queue: Dict[TaskPriority, deque] = {
            priority: deque() for priority in TaskPriority
        }
        self.active_tasks: Dict[str, Task] = {}
        self.completed_tasks: deque = deque(maxlen=10000)
        self.failed_tasks: deque = deque(maxlen=1000)
        
        # System state
        self.system_insights: deque = deque(maxlen=5000)
        self.system_metrics: Dict[str, Any] = {}
        self.configuration: Dict[str, Any] = {}
        
        # Performance tracking
        self.total_tasks_processed = 0
        self.start_time = datetime.now()
        self.last_health_check = datetime.now()
        
        logger.info("UX-MIRROR Core Orchestrator initialized")
    
    async def start(self):
        """Start the orchestrator server and background tasks"""
        logger.info(f"Starting UX-MIRROR Orchestrator on {self.host}:{self.port}")
        
        # Load configuration
        await self._load_configuration()
        
        # Start WebSocket server
        self.server = await websockets.serve(
            self._handle_agent_connection,
            self.host,
            self.port
        )
        
        logger.info(f"Orchestrator server listening on ws://{self.host}:{self.port}")
        
        # Start background tasks
        background_tasks = [
            self._process_task_queue(),
            self._monitor_agent_health(),
            self._generate_insights(),
            self._system_health_monitoring(),
            self._cleanup_old_data(),
            self._save_metrics_periodically()
        ]
        
        await asyncio.gather(*background_tasks)
    
    async def _load_configuration(self):
        """Load orchestrator configuration"""
        try:
            with open("config/orchestrator_config.json", "r") as f:
                self.configuration = json.load(f)
                logger.info("Orchestrator configuration loaded successfully")
        except FileNotFoundError:
            logger.warning("Orchestrator config not found, using defaults")
            self.configuration = {
                "task_processing": {
                    "max_concurrent_tasks": 50,
                    "task_timeout": 300,
                    "max_retries": 3,
                    "load_balance_strategy": "least_loaded"
                },
                "agent_management": {
                    "heartbeat_timeout": 30,
                    "max_load_threshold": 0.8,
                    "health_check_interval": 10
                },
                "insights": {
                    "generation_interval": 60,
                    "confidence_threshold": 0.7,
                    "max_insights_per_minute": 10
                },
                "monitoring": {
                    "metrics_save_interval": 300,
                    "cleanup_interval": 3600,
                    "max_log_retention_days": 7
                }
            }
    
    async def _handle_agent_connection(self, websocket, path=None):
        """Handle new agent connections"""
        agent_id = None
        try:
            logger.info(f"New agent connection from {websocket.remote_address}")
            
            # Wait for registration message
            registration_message = await asyncio.wait_for(
                websocket.recv(), 
                timeout=30
            )
            
            registration_data = json.loads(registration_message)
            agent_id = registration_data.get("agent_id")
            capabilities = registration_data.get("capabilities", [])
            
            if not agent_id:
                await websocket.send(json.dumps({
                    "type": "error",
                    "message": "Missing agent_id in registration"
                }))
                return
            
            # Register the agent
            agent_info = AgentInfo(
                agent_id=agent_id,
                websocket=websocket,
                capabilities=capabilities,
                status=AgentStatus.ACTIVE,
                last_heartbeat=datetime.now(),
                current_load=0.0,
                total_tasks_completed=0,
                avg_response_time=0.0,
                error_count=0,
                registration_time=datetime.now()
            )
            
            self.connected_agents[agent_id] = agent_info
            self.agent_capabilities[agent_id] = set(capabilities)
            
            # Send confirmation
            await websocket.send(json.dumps({
                "type": "registration_confirmed",
                "agent_id": agent_id,
                "server_time": datetime.now().isoformat()
            }))
            
            logger.info(f"Agent {agent_id} registered with capabilities: {capabilities}")
            
            # Handle agent messages
            await self._handle_agent_messages(agent_id, websocket)
            
        except asyncio.TimeoutError:
            logger.warning("Agent registration timeout")
        except websockets.exceptions.ConnectionClosed:
            if agent_id:
                logger.info(f"Agent {agent_id} disconnected")
        except Exception as e:
            logger.error(f"Error handling agent connection: {e}")
        finally:
            # Clean up agent registration
            if agent_id and agent_id in self.connected_agents:
                self.connected_agents[agent_id].status = AgentStatus.DISCONNECTED
                del self.connected_agents[agent_id]
                if agent_id in self.agent_capabilities:
                    del self.agent_capabilities[agent_id]
                logger.info(f"Cleaned up registration for agent {agent_id}")
    
    async def _handle_agent_messages(self, agent_id: str, websocket):
        """Handle messages from a connected agent"""
        try:
            async for message in websocket:
                try:
                    data = json.loads(message)
                    message_type = data.get("type")
                    
                    # Update last heartbeat
                    if agent_id in self.connected_agents:
                        self.connected_agents[agent_id].last_heartbeat = datetime.now()
                    
                    # Route message based on type
                    if message_type == "heartbeat":
                        await self._handle_heartbeat(agent_id, data)
                    elif message_type == "task_result":
                        await self._handle_task_result(agent_id, data)
                    elif message_type == "alert":
                        await self._handle_agent_alert(agent_id, data)
                    elif message_type == "recommendation":
                        await self._handle_agent_recommendation(agent_id, data)
                    elif message_type == "response":
                        await self._handle_agent_response(agent_id, data)
                    else:
                        logger.warning(f"Unknown message type from {agent_id}: {message_type}")
                        
                except json.JSONDecodeError:
                    logger.error(f"Invalid JSON from agent {agent_id}")
                except Exception as e:
                    logger.error(f"Error processing message from {agent_id}: {e}")
                    
        except websockets.exceptions.ConnectionClosed:
            logger.info(f"Agent {agent_id} connection closed")
        except Exception as e:
            logger.error(f"Error in message handling for {agent_id}: {e}")
    
    async def _handle_heartbeat(self, agent_id: str, data: Dict[str, Any]):
        """Handle heartbeat messages from agents"""
        if agent_id not in self.connected_agents:
            return
        
        agent = self.connected_agents[agent_id]
        
        # Update agent status
        agent.status = AgentStatus.ACTIVE if data.get("status") == "active" else AgentStatus.ERROR
        agent.current_load = data.get("cpu_usage", 0.0) / 100.0  # Normalize to 0-1
        
        # Update performance metrics
        memory_usage = data.get("memory_usage", 0)
        queue_size = data.get("analysis_queue_size", 0)
        
        # Log high resource usage
        if agent.current_load > 0.8:
            logger.warning(f"Agent {agent_id} high CPU usage: {agent.current_load:.2f}")
            agent.status = AgentStatus.OVERLOADED
        
        if memory_usage > 85:
            logger.warning(f"Agent {agent_id} high memory usage: {memory_usage}%")
    
    async def _handle_task_result(self, agent_id: str, data: Dict[str, Any]):
        """Handle task completion results from agents"""
        task_id = data.get("task_id")
        status = data.get("status")
        result = data.get("result")
        
        if task_id not in self.active_tasks:
            logger.warning(f"Received result for unknown task {task_id} from {agent_id}")
            return
        
        task = self.active_tasks[task_id]
        task.status = status
        
        if status == "completed":
            # Task completed successfully
            task.data["result"] = result
            self.completed_tasks.append(task)
            
            # Update agent metrics
            if agent_id in self.connected_agents:
                agent = self.connected_agents[agent_id]
                agent.total_tasks_completed += 1
                
                # Update average response time
                response_time = (datetime.now() - task.created_at).total_seconds()
                if agent.avg_response_time == 0:
                    agent.avg_response_time = response_time
                else:
                    agent.avg_response_time = (agent.avg_response_time + response_time) / 2
            
            logger.info(f"Task {task_id} completed successfully by {agent_id}")
            
        elif status == "failed":
            # Task failed
            error_message = data.get("error", "Unknown error")
            logger.error(f"Task {task_id} failed on {agent_id}: {error_message}")
            
            # Retry logic
            if task.retry_count < task.max_retries:
                task.retry_count += 1
                task.status = "pending"
                task.assigned_agent = None
                
                # Add back to queue for retry
                self.task_queue[task.priority].append(task)
                logger.info(f"Task {task_id} queued for retry ({task.retry_count}/{task.max_retries})")
            else:
                # Max retries exceeded
                task.status = "failed"
                self.failed_tasks.append(task)
                logger.error(f"Task {task_id} failed permanently after {task.max_retries} retries")
            
            # Update agent error count
            if agent_id in self.connected_agents:
                self.connected_agents[agent_id].error_count += 1
        
        # Remove from active tasks
        if task_id in self.active_tasks:
            del self.active_tasks[task_id]
        
        self.total_tasks_processed += 1
    
    async def _handle_agent_alert(self, agent_id: str, data: Dict[str, Any]):
        """Handle alerts from agents"""
        alert_type = data.get("alert_type")
        severity = data.get("severity", "medium")
        alert_data = data.get("data", {})
        
        logger.warning(f"Alert from {agent_id}: {alert_type} (severity: {severity})")
        
        # Create insight from alert
        insight = UXInsight(
            insight_id=str(uuid.uuid4()),
            type=f"alert_{alert_type}",
            severity=severity,
            description=f"Alert from {agent_id}: {alert_type}",
            source_agents=[agent_id],
            confidence=0.9,  # Alerts have high confidence
            data=alert_data,
            created_at=datetime.now()
        )
        
        self.system_insights.append(insight)
        
        # Take immediate action for critical alerts
        if severity == "critical":
            await self._handle_critical_alert(agent_id, alert_type, alert_data)
    
    async def _handle_agent_recommendation(self, agent_id: str, data: Dict[str, Any]):
        """Handle recommendations from agents"""
        recommendation_type = data.get("recommendation_type")
        priority = data.get("priority", "medium")
        recommendation_data = data.get("data", {})
        
        logger.info(f"Recommendation from {agent_id}: {recommendation_type} (priority: {priority})")
        
        # Create insight from recommendation
        insight = UXInsight(
            insight_id=str(uuid.uuid4()),
            type=f"recommendation_{recommendation_type}",
            severity=priority,
            description=f"Recommendation from {agent_id}: {recommendation_type}",
            source_agents=[agent_id],
            confidence=0.7,  # Recommendations have medium confidence
            data=recommendation_data,
            created_at=datetime.now()
        )
        
        self.system_insights.append(insight)
    
    async def _handle_agent_response(self, agent_id: str, data: Dict[str, Any]):
        """Handle responses to orchestrator requests"""
        request_id = data.get("request_id")
        status = data.get("status")
        
        logger.info(f"Response from {agent_id} for request {request_id}: {status}")
        
        # Handle specific response types as needed
        # This can be extended for specific request-response patterns
    
    async def _handle_critical_alert(self, agent_id: str, alert_type: str, alert_data: Dict[str, Any]):
        """Handle critical alerts requiring immediate action"""
        logger.critical(f"CRITICAL ALERT from {agent_id}: {alert_type}")
        
        # Example critical alert handling
        if alert_type == "critical_ux_issues":
            # Create high-priority task for immediate analysis
            task = Task(
                task_id=str(uuid.uuid4()),
                task_type="urgent_analysis",
                priority=TaskPriority.CRITICAL,
                data={
                    "source_alert": alert_data,
                    "source_agent": agent_id,
                    "action_required": "immediate_review"
                },
                assigned_agent=None,
                created_at=datetime.now(),
                deadline=datetime.now() + timedelta(minutes=5),
                retry_count=0,
                max_retries=2,
                status="pending"
            )
            
            self.task_queue[TaskPriority.CRITICAL].append(task)
            logger.info(f"Created critical task {task.task_id} for alert {alert_type}")
    
    def create_task(self, task_type: str, data: Dict[str, Any], 
                   priority: TaskPriority = TaskPriority.MEDIUM,
                   deadline: Optional[datetime] = None) -> str:
        """Create a new task and add it to the queue"""
        task_id = str(uuid.uuid4())
        
        task = Task(
            task_id=task_id,
            task_type=task_type,
            priority=priority,
            data=data,
            assigned_agent=None,
            created_at=datetime.now(),
            deadline=deadline,
            retry_count=0,
            max_retries=self.configuration["task_processing"]["max_retries"],
            status="pending"
        )
        
        self.task_queue[priority].append(task)
        logger.info(f"Created task {task_id} of type {task_type} with priority {priority.name}")
        
        return task_id
    
    async def stop(self):
        """Stop the orchestrator server"""
        if self.server:
            self.server.close()
            await self.server.wait_closed()
        logger.info("Orchestrator server stopped")

    async def _process_task_queue(self):
        """Process tasks from the queue and assign them to agents"""
        while True:
            try:
                # Process tasks by priority (CRITICAL -> HIGH -> MEDIUM -> LOW)
                for priority in [TaskPriority.CRITICAL, TaskPriority.HIGH, 
                               TaskPriority.MEDIUM, TaskPriority.LOW]:
                    
                    if not self.task_queue[priority]:
                        continue
                    
                    # Check if we have capacity for more tasks
                    max_concurrent = self.configuration["task_processing"]["max_concurrent_tasks"]
                    if len(self.active_tasks) >= max_concurrent:
                        break
                    
                    # Get next task
                    task = self.task_queue[priority].popleft()
                    
                    # Find best agent for this task
                    agent_id = await self._select_agent_for_task(task)
                    
                    if agent_id:
                        # Assign task to agent
                        await self._assign_task_to_agent(task, agent_id)
                    else:
                        # No suitable agent available, put task back
                        self.task_queue[priority].appendleft(task)
                        logger.warning(f"No suitable agent for task {task.task_id}, requeuing")
                
                await asyncio.sleep(1)  # Process every second
                
            except Exception as e:
                logger.error(f"Error in task processing: {e}")
                await asyncio.sleep(5)
    
    async def _select_agent_for_task(self, task: Task) -> Optional[str]:
        """Select the best agent for a given task using load balancing"""
        
        # Find agents with required capabilities
        required_capabilities = self._get_required_capabilities(task.task_type)
        suitable_agents = []
        
        for agent_id, agent in self.connected_agents.items():
            # Check if agent is active and has required capabilities
            if (agent.status == AgentStatus.ACTIVE and 
                required_capabilities.issubset(self.agent_capabilities[agent_id])):
                
                # Check load threshold
                max_load = self.configuration["agent_management"]["max_load_threshold"]
                if agent.current_load < max_load:
                    suitable_agents.append((agent_id, agent))
        
        if not suitable_agents:
            return None
        
        # Apply load balancing strategy
        strategy = self.configuration["task_processing"]["load_balance_strategy"]
        
        if strategy == "least_loaded":
            # Select agent with lowest current load
            return min(suitable_agents, key=lambda x: x[1].current_load)[0]
        
        elif strategy == "round_robin":
            # Simple round robin based on total tasks completed
            return min(suitable_agents, key=lambda x: x[1].total_tasks_completed)[0]
        
        elif strategy == "fastest_response":
            # Select agent with best average response time
            return min(suitable_agents, key=lambda x: x[1].avg_response_time or float('inf'))[0]
        
        else:
            # Default to first suitable agent
            return suitable_agents[0][0]
    
    def _get_required_capabilities(self, task_type: str) -> Set[str]:
        """Get required capabilities for a task type"""
        capability_map = {
            "screenshot_analysis": {"screenshot_analysis", "ui_element_detection"},
            "urgent_analysis": {"screenshot_analysis", "accessibility_assessment"},
            "custom_recognizer_training": {"custom_recognizer_training"},
            "behavior_analysis": {"user_behavior_tracking", "pattern_analysis"},
            "performance_optimization": {"performance_analysis", "resource_optimization"},
            "accessibility_audit": {"accessibility_assessment", "ui_element_detection"},
            "cross_platform_test": {"cross_platform_visual_testing"}
        }
        
        return set(capability_map.get(task_type, set()))
    
    async def _assign_task_to_agent(self, task: Task, agent_id: str):
        """Assign a task to a specific agent"""
        try:
            agent = self.connected_agents[agent_id]
            
            # Update task status
            task.assigned_agent = agent_id
            task.status = "assigned"
            self.active_tasks[task.task_id] = task
            
            # Send task to agent
            task_message = {
                "type": task.task_type,
                "task_id": task.task_id,
                "priority": task.priority.name,
                "data": task.data,
                "deadline": task.deadline.isoformat() if task.deadline else None
            }
            
            await agent.websocket.send(json.dumps(task_message, default=str))
            logger.info(f"Assigned task {task.task_id} to agent {agent_id}")
            
        except Exception as e:
            logger.error(f"Error assigning task {task.task_id} to {agent_id}: {e}")
            # Put task back in queue
            task.status = "pending"
            task.assigned_agent = None
            self.task_queue[task.priority].append(task)
    
    async def _monitor_agent_health(self):
        """Monitor agent health and handle disconnections"""
        while True:
            try:
                current_time = datetime.now()
                timeout_threshold = timedelta(
                    seconds=self.configuration["agent_management"]["heartbeat_timeout"]
                )
                
                # Check for inactive agents
                inactive_agents = []
                for agent_id, agent in self.connected_agents.items():
                    if current_time - agent.last_heartbeat > timeout_threshold:
                        inactive_agents.append(agent_id)
                        logger.warning(f"Agent {agent_id} heartbeat timeout")
                
                # Handle inactive agents
                for agent_id in inactive_agents:
                    await self._handle_agent_disconnect(agent_id)
                
                # Check for overloaded agents
                for agent_id, agent in self.connected_agents.items():
                    if agent.status == AgentStatus.OVERLOADED:
                        await self._handle_overloaded_agent(agent_id)
                
                # Health check interval
                interval = self.configuration["agent_management"]["health_check_interval"]
                await asyncio.sleep(interval)
                
            except Exception as e:
                logger.error(f"Error in agent health monitoring: {e}")
                await asyncio.sleep(10)
    
    async def _handle_agent_disconnect(self, agent_id: str):
        """Handle agent disconnection and reassign tasks"""
        if agent_id not in self.connected_agents:
            return
        
        logger.warning(f"Handling disconnect for agent {agent_id}")
        
        # Find tasks assigned to this agent
        orphaned_tasks = []
        for task_id, task in list(self.active_tasks.items()):
            if task.assigned_agent == agent_id:
                orphaned_tasks.append(task)
                del self.active_tasks[task_id]
        
        # Reassign orphaned tasks
        for task in orphaned_tasks:
            task.assigned_agent = None
            task.status = "pending"
            self.task_queue[task.priority].append(task)
            logger.info(f"Reassigned orphaned task {task.task_id}")
        
        # Update agent status
        self.connected_agents[agent_id].status = AgentStatus.DISCONNECTED
    
    async def _handle_overloaded_agent(self, agent_id: str):
        """Handle overloaded agent by reducing its load"""
        logger.warning(f"Agent {agent_id} is overloaded, reducing load")
        
        # Find tasks assigned to this agent and reassign some
        agent_tasks = [
            task for task in self.active_tasks.values() 
            if task.assigned_agent == agent_id and task.priority != TaskPriority.CRITICAL
        ]
        
        # Reassign non-critical tasks
        tasks_to_reassign = agent_tasks[:len(agent_tasks)//2]  # Reassign half
        
        for task in tasks_to_reassign:
            # Remove from active tasks and reassign
            if task.task_id in self.active_tasks:
                del self.active_tasks[task.task_id]
            
            task.assigned_agent = None
            task.status = "pending"
            self.task_queue[task.priority].append(task)
            logger.info(f"Reassigned task {task.task_id} from overloaded agent {agent_id}")
    
    async def _generate_insights(self):
        """Generate system insights from collected data"""
        while True:
            try:
                # Generate insights every minute
                await asyncio.sleep(self.configuration["insights"]["generation_interval"])
                
                # Analyze recent tasks and patterns
                insights = await self._analyze_system_patterns()
                
                # Add insights to system insights
                for insight in insights:
                    self.system_insights.append(insight)
                
                # Limit insights generation rate
                max_insights = self.configuration["insights"]["max_insights_per_minute"]
                if len(insights) > max_insights:
                    logger.warning(f"Generated {len(insights)} insights, exceeding limit of {max_insights}")
                
            except Exception as e:
                logger.error(f"Error generating insights: {e}")
                await asyncio.sleep(60)
    
    async def _analyze_system_patterns(self) -> List[UXInsight]:
        """Analyze system patterns and generate insights"""
        insights = []
        current_time = datetime.now()
        
        # Analyze task completion patterns
        recent_tasks = [
            task for task in self.completed_tasks 
            if (current_time - task.created_at).total_seconds() < 3600  # Last hour
        ]
        
        if recent_tasks:
            # Calculate average task completion time
            avg_completion_time = sum(
                (task.data.get("completion_time", 0) for task in recent_tasks)
            ) / len(recent_tasks)
            
            if avg_completion_time > 60:  # More than 1 minute average
                insights.append(UXInsight(
                    insight_id=str(uuid.uuid4()),
                    type="performance_degradation",
                    severity="medium",
                    description=f"Average task completion time increased to {avg_completion_time:.1f}s",
                    source_agents=["orchestrator"],
                    confidence=0.8,
                    data={"avg_completion_time": avg_completion_time, "task_count": len(recent_tasks)},
                    created_at=current_time
                ))
        
        # Analyze agent performance
        for agent_id, agent in self.connected_agents.items():
            if agent.error_count > 5:  # High error rate
                insights.append(UXInsight(
                    insight_id=str(uuid.uuid4()),
                    type="agent_reliability_issue",
                    severity="high",
                    description=f"Agent {agent_id} has high error rate: {agent.error_count} errors",
                    source_agents=["orchestrator"],
                    confidence=0.9,
                    data={"agent_id": agent_id, "error_count": agent.error_count},
                    created_at=current_time
                ))
        
        # Analyze failed tasks
        recent_failures = [
            task for task in self.failed_tasks
            if (current_time - task.created_at).total_seconds() < 3600
        ]
        
        if len(recent_failures) > 10:  # High failure rate
            insights.append(UXInsight(
                insight_id=str(uuid.uuid4()),
                type="high_task_failure_rate",
                severity="high",
                description=f"High task failure rate: {len(recent_failures)} failures in last hour",
                source_agents=["orchestrator"],
                confidence=0.85,
                data={"failure_count": len(recent_failures), "time_window": "1_hour"},
                created_at=current_time
            ))
        
        return insights
    
    async def _system_health_monitoring(self):
        """Monitor overall system health and performance"""
        while True:
            try:
                current_time = datetime.now()
                
                # Update system metrics
                self.system_metrics.update({
                    "connected_agents": len(self.connected_agents),
                    "active_tasks": len(self.active_tasks),
                    "total_insights": len(self.system_insights),
                    "uptime_hours": (current_time - self.start_time).total_seconds() / 3600,
                    "tasks_processed": self.total_tasks_processed,
                    "system_load": psutil.cpu_percent(),
                    "memory_usage": psutil.virtual_memory().percent,
                    "timestamp": current_time.isoformat()
                })
                
                # Log system status
                if current_time.minute % 5 == 0:  # Every 5 minutes
                    logger.info(
                        f"System Status - Agents: {len(self.connected_agents)}, "
                        f"Active Tasks: {len(self.active_tasks)}, "
                        f"Uptime: {self.system_metrics['uptime_hours']:.1f}h"
                    )
                
                # Check system health thresholds
                if self.system_metrics["memory_usage"] > 90:
                    logger.warning(f"High system memory usage: {self.system_metrics['memory_usage']}%")
                
                if len(self.active_tasks) > self.configuration["task_processing"]["max_concurrent_tasks"] * 0.9:
                    logger.warning(f"Approaching task capacity: {len(self.active_tasks)} active tasks")
                
                self.last_health_check = current_time
                await asyncio.sleep(30)  # Check every 30 seconds
                
            except Exception as e:
                logger.error(f"Error in system health monitoring: {e}")
                await asyncio.sleep(60)
    
    async def _cleanup_old_data(self):
        """Clean up old data to prevent memory leaks"""
        while True:
            try:
                cleanup_interval = self.configuration["monitoring"]["cleanup_interval"]
                await asyncio.sleep(cleanup_interval)
                
                current_time = datetime.now()
                retention_days = self.configuration["monitoring"]["max_log_retention_days"]
                cutoff_time = current_time - timedelta(days=retention_days)
                
                # Clean up old insights
                old_insights = [
                    insight for insight in self.system_insights
                    if insight.created_at < cutoff_time
                ]
                
                for insight in old_insights:
                    self.system_insights.remove(insight)
                
                if old_insights:
                    logger.info(f"Cleaned up {len(old_insights)} old insights")
                
                # Clean up old completed tasks (keep in memory for shorter time)
                hour_ago = current_time - timedelta(hours=1)
                old_completed = [
                    task for task in self.completed_tasks
                    if task.created_at < hour_ago
                ]
                
                for task in old_completed:
                    self.completed_tasks.remove(task)
                
                if old_completed:
                    logger.info(f"Cleaned up {len(old_completed)} old completed tasks")
                
            except Exception as e:
                logger.error(f"Error in data cleanup: {e}")
                await asyncio.sleep(3600)  # Retry in 1 hour
    
    async def _save_metrics_periodically(self):
        """Save system metrics to file periodically"""
        while True:
            try:
                interval = self.configuration["monitoring"]["metrics_save_interval"]
                await asyncio.sleep(interval)
                
                # Save current metrics to file
                metrics_file = f"logs/metrics_{datetime.now().strftime('%Y%m%d')}.json"
                
                try:
                    import os
                    os.makedirs("logs", exist_ok=True)
                    
                    with open(metrics_file, "a") as f:
                        f.write(json.dumps(self.system_metrics, default=str) + "\n")
                    
                    logger.debug("System metrics saved to file")
                    
                except Exception as e:
                    logger.error(f"Failed to save metrics: {e}")
                
            except Exception as e:
                logger.error(f"Error in metrics saving: {e}")
                await asyncio.sleep(300)  # Retry in 5 minutes
    
    def get_system_status(self) -> Dict[str, Any]:
        """Get current system status"""
        return {
            "orchestrator": {
                "status": "active",
                "uptime": (datetime.now() - self.start_time).total_seconds(),
                "last_health_check": self.last_health_check.isoformat()
            },
            "agents": {
                agent_id: {
                    "status": agent.status.value,
                    "capabilities": list(agent.capabilities),
                    "current_load": agent.current_load,
                    "tasks_completed": agent.total_tasks_completed,
                    "error_count": agent.error_count,
                    "avg_response_time": agent.avg_response_time
                }
                for agent_id, agent in self.connected_agents.items()
            },
            "tasks": {
                "active": len(self.active_tasks),
                "queued": sum(len(queue) for queue in self.task_queue.values()),
                "completed": len(self.completed_tasks),
                "failed": len(self.failed_tasks),
                "total_processed": self.total_tasks_processed
            },
            "insights": {
                "total": len(self.system_insights),
                "recent": len([
                    i for i in self.system_insights 
                    if (datetime.now() - i.created_at).total_seconds() < 3600
                ])
            },
            "system": self.system_metrics
        }

def main():
    """Main entry point for the Orchestrator Agent"""
    orchestrator = OrchestratorAgent()
    
    try:
        asyncio.run(orchestrator.start())
    except KeyboardInterrupt:
        logger.info("Orchestrator shutting down...")
    except Exception as e:
        logger.error(f"Orchestrator error: {e}")

if __name__ == "__main__":
    main() 